{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "# 准备数据集\n",
    "data = [[i+j for j in range(5)] for i in range(1000)]\n",
    "# target = [[i+j+1 for j in range(5)] for i in range(100)]\n",
    "target=np.zeros((1000,2))\n",
    "for i in range(1000):\n",
    "    target[i][0] = sum(data[i])\n",
    "    target[i][1] = data[i][0]-data[i][1]+data[i][2]-data[i][3]+data[i][4]\n",
    "data = np.array(data, dtype=float)\n",
    "target = np.array(target, dtype=float)\n",
    "# 标准化数据\n",
    "data /= np.max(data)\n",
    "target /= np.max(target)\n",
    "print(np.max(data),np.min(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "13/13 - 2s - loss: 0.0582 - 2s/epoch - 161ms/step\n",
      "Epoch 2/100\n",
      "13/13 - 0s - loss: 0.0097 - 45ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "13/13 - 0s - loss: 0.0032 - 42ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "13/13 - 0s - loss: 0.0014 - 43ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "13/13 - 0s - loss: 6.0709e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "13/13 - 0s - loss: 1.8332e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "13/13 - 0s - loss: 5.0030e-05 - 43ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "13/13 - 0s - loss: 2.5209e-05 - 41ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "13/13 - 0s - loss: 2.2781e-05 - 43ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "13/13 - 0s - loss: 2.1473e-05 - 46ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "13/13 - 0s - loss: 1.9466e-05 - 45ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "13/13 - 0s - loss: 1.8497e-05 - 42ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "13/13 - 0s - loss: 1.7431e-05 - 42ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "13/13 - 0s - loss: 1.6661e-05 - 45ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "13/13 - 0s - loss: 1.5719e-05 - 41ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "13/13 - 0s - loss: 1.4849e-05 - 42ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "13/13 - 0s - loss: 1.4009e-05 - 46ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "13/13 - 0s - loss: 1.3212e-05 - 44ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "13/13 - 0s - loss: 1.2435e-05 - 42ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "13/13 - 0s - loss: 1.1658e-05 - 112ms/epoch - 9ms/step\n",
      "Epoch 21/100\n",
      "13/13 - 0s - loss: 1.1165e-05 - 78ms/epoch - 6ms/step\n",
      "Epoch 22/100\n",
      "13/13 - 0s - loss: 1.0235e-05 - 52ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "13/13 - 0s - loss: 9.6388e-06 - 47ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "13/13 - 0s - loss: 8.9151e-06 - 43ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "13/13 - 0s - loss: 8.2565e-06 - 41ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "13/13 - 0s - loss: 7.6033e-06 - 48ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "13/13 - 0s - loss: 7.1503e-06 - 44ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "13/13 - 0s - loss: 6.6343e-06 - 41ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "13/13 - 0s - loss: 6.1181e-06 - 51ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "13/13 - 0s - loss: 5.7036e-06 - 45ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "13/13 - 0s - loss: 5.1785e-06 - 44ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "13/13 - 0s - loss: 4.8310e-06 - 43ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "13/13 - 0s - loss: 4.4537e-06 - 45ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "13/13 - 0s - loss: 4.0750e-06 - 44ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "13/13 - 0s - loss: 3.7101e-06 - 43ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "13/13 - 0s - loss: 3.4163e-06 - 44ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "13/13 - 0s - loss: 3.1820e-06 - 42ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "13/13 - 0s - loss: 2.8847e-06 - 44ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "13/13 - 0s - loss: 2.6335e-06 - 41ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "13/13 - 0s - loss: 2.4588e-06 - 41ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "13/13 - 0s - loss: 2.2074e-06 - 42ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "13/13 - 0s - loss: 2.0728e-06 - 43ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "13/13 - 0s - loss: 1.9056e-06 - 42ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "13/13 - 0s - loss: 1.7197e-06 - 40ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "13/13 - 0s - loss: 1.5743e-06 - 43ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "13/13 - 0s - loss: 1.4451e-06 - 39ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "13/13 - 0s - loss: 1.3349e-06 - 40ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "13/13 - 0s - loss: 1.2212e-06 - 41ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "13/13 - 0s - loss: 1.1500e-06 - 43ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "13/13 - 0s - loss: 1.0489e-06 - 84ms/epoch - 6ms/step\n",
      "Epoch 51/100\n",
      "13/13 - 0s - loss: 9.8762e-07 - 43ms/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "13/13 - 0s - loss: 9.2562e-07 - 43ms/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "13/13 - 0s - loss: 8.4276e-07 - 47ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "13/13 - 0s - loss: 7.8464e-07 - 44ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "13/13 - 0s - loss: 7.2997e-07 - 41ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "13/13 - 0s - loss: 6.8430e-07 - 41ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "13/13 - 0s - loss: 6.4526e-07 - 42ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "13/13 - 0s - loss: 6.1506e-07 - 53ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "13/13 - 0s - loss: 5.7402e-07 - 43ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "13/13 - 0s - loss: 5.4263e-07 - 42ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "13/13 - 0s - loss: 5.1559e-07 - 40ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "13/13 - 0s - loss: 4.8659e-07 - 44ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "13/13 - 0s - loss: 4.6180e-07 - 43ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "13/13 - 0s - loss: 4.5310e-07 - 40ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "13/13 - 0s - loss: 4.3448e-07 - 42ms/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "13/13 - 0s - loss: 4.1300e-07 - 44ms/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "13/13 - 0s - loss: 3.9626e-07 - 41ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "13/13 - 0s - loss: 3.8003e-07 - 49ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "13/13 - 0s - loss: 3.7606e-07 - 41ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "13/13 - 0s - loss: 3.5269e-07 - 43ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "13/13 - 0s - loss: 3.4239e-07 - 42ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "13/13 - 0s - loss: 3.3808e-07 - 39ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "13/13 - 0s - loss: 3.2511e-07 - 38ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "13/13 - 0s - loss: 3.1725e-07 - 43ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "13/13 - 0s - loss: 3.1592e-07 - 42ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "13/13 - 0s - loss: 3.0757e-07 - 43ms/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "13/13 - 0s - loss: 2.9937e-07 - 43ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "13/13 - 0s - loss: 3.0935e-07 - 40ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "13/13 - 0s - loss: 2.9633e-07 - 39ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "13/13 - 0s - loss: 2.8560e-07 - 47ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "13/13 - 0s - loss: 2.8112e-07 - 43ms/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "13/13 - 0s - loss: 2.7642e-07 - 45ms/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "13/13 - 0s - loss: 2.8215e-07 - 39ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "13/13 - 0s - loss: 2.7492e-07 - 42ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "13/13 - 0s - loss: 2.8191e-07 - 40ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "13/13 - 0s - loss: 2.8014e-07 - 44ms/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "13/13 - 0s - loss: 2.8909e-07 - 78ms/epoch - 6ms/step\n",
      "Epoch 88/100\n",
      "13/13 - 0s - loss: 2.6648e-07 - 42ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "13/13 - 0s - loss: 2.6376e-07 - 40ms/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "13/13 - 0s - loss: 2.7115e-07 - 41ms/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "13/13 - 0s - loss: 2.6856e-07 - 39ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "13/13 - 0s - loss: 2.6073e-07 - 48ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "13/13 - 0s - loss: 2.6945e-07 - 42ms/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "13/13 - 0s - loss: 2.6731e-07 - 41ms/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "13/13 - 0s - loss: 2.5665e-07 - 40ms/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "13/13 - 0s - loss: 2.5171e-07 - 40ms/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "13/13 - 0s - loss: 2.5222e-07 - 42ms/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "13/13 - 0s - loss: 2.5133e-07 - 41ms/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "13/13 - 0s - loss: 2.4747e-07 - 42ms/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "13/13 - 0s - loss: 2.5381e-07 - 43ms/epoch - 3ms/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000027003C9DE50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "[[0.52268296 0.1047539 ]\n",
      " [0.73920053 0.14808954]\n",
      " [0.7421964  0.14868708]\n",
      " [0.66217095 0.1327027 ]\n",
      " [0.41221455 0.08257381]\n",
      " [0.680199   0.13630748]\n",
      " [0.6280894  0.12588271]\n",
      " [0.5146471  0.10314133]\n",
      " [0.8606146  0.17224604]\n",
      " [0.13770005 0.02750131]\n",
      " [0.8129556  0.16277955]\n",
      " [0.07843551 0.01565858]\n",
      " [0.63811696 0.12789004]\n",
      " [0.97308826 0.19449279]\n",
      " [0.9386753  0.18770106]\n",
      " [0.90020216 0.18009202]\n",
      " [0.28098938 0.05622046]\n",
      " [0.884382   0.17695844]\n",
      " [0.7631545  0.15286544]\n",
      " [0.31999275 0.06405099]\n",
      " [0.5508058  0.11039561]\n",
      " [0.17538153 0.03504376]\n",
      " [0.372088   0.0745138 ]\n",
      " [0.52870965 0.10596311]\n",
      " [0.21117285 0.04221531]\n",
      " [0.23607604 0.04720875]\n",
      " [0.10309228 0.02058246]\n",
      " [0.98584104 0.19700608]\n",
      " [0.9031661  0.1806788 ]\n",
      " [0.9475349  0.18945085]\n",
      " [0.34703085 0.06948094]\n",
      " [0.14067097 0.02809566]\n",
      " [0.62307465 0.1248787 ]\n",
      " [0.500584   0.10031889]\n",
      " [0.37108538 0.07431239]\n",
      " [0.19923297 0.03982216]\n",
      " [0.6892086  0.13810815]\n",
      " [0.5859479  0.11744121]\n",
      " [0.90217817 0.18048319]\n",
      " [0.06170075 0.01231961]\n",
      " [0.32900247 0.06586027]\n",
      " [0.0981566  0.01959643]\n",
      " [0.31298742 0.0626443 ]\n",
      " [0.97406983 0.19468635]\n",
      " [0.29998276 0.06003325]\n",
      " [0.27799192 0.05561884]\n",
      " [0.9248792  0.18497433]\n",
      " [0.6030097  0.12085997]\n",
      " [0.44032264 0.08821929]\n",
      " [0.83879066 0.16791378]\n",
      " [0.5718931  0.11462399]\n",
      " [0.8804239  0.17617409]\n",
      " [0.26201305 0.05241212]\n",
      " [0.5799247  0.116234  ]\n",
      " [0.02635252 0.00527522]\n",
      " [0.03321589 0.00664206]\n",
      " [0.6190625  0.12407527]\n",
      " [0.01361935 0.00274068]\n",
      " [0.22212565 0.04441117]\n",
      " [0.82190365 0.16455851]\n",
      " [0.29698268 0.05943095]\n",
      " [0.05678384 0.01133904]\n",
      " [0.5437756  0.10898554]\n",
      " [0.21017754 0.04201579]\n",
      " [0.60602    0.12146302]\n",
      " [0.6942126  0.13910805]\n",
      " [0.6641746  0.13310349]\n",
      " [0.86755127 0.17362197]\n",
      " [0.07252611 0.01447925]\n",
      " [0.54477996 0.109187  ]\n",
      " [0.10901792 0.0217665 ]\n",
      " [0.49455696 0.09910911]\n",
      " [0.5919703  0.11864812]\n",
      " [0.74319494 0.14888622]\n",
      " [0.2929833  0.05862805]\n",
      " [0.28998414 0.058026  ]\n",
      " [0.6541549  0.1310993 ]\n",
      " [0.04204735 0.0084015 ]\n",
      " [0.5909666  0.11844698]\n",
      " [0.30798474 0.06163983]\n",
      " [0.68120027 0.1365076 ]\n",
      " [0.06858832 0.01369355]\n",
      " [0.27599385 0.05521781]\n",
      " [0.06957264 0.01388993]\n",
      " [0.31899187 0.06385   ]\n",
      " [0.5498015  0.11019419]\n",
      " [0.99759835 0.19932145]\n",
      " [0.71621794 0.14350305]\n",
      " [0.7551732  0.15127462]\n",
      " [0.32800126 0.06565922]\n",
      " [0.38311893 0.07672949]\n",
      " [0.45237246 0.09063927]\n",
      " [0.52368736 0.10495542]\n",
      " [0.21913779 0.04381211]\n",
      " [0.78906953 0.15802713]\n",
      " [0.4373105  0.08761435]\n",
      " [0.7661467  0.15346171]\n",
      " [0.09026396 0.01802007]\n",
      " [0.06563595 0.01310456]\n",
      " [0.82786596 0.16574347]\n",
      " [0.7182174  0.14390224]\n",
      " [0.3520407  0.07048718]\n",
      " [0.93670547 0.18731184]\n",
      " [0.25702238 0.05141074]\n",
      " [0.6371143  0.12768927]\n",
      " [0.6461369  0.12949501]\n",
      " [0.555827   0.11140261]\n",
      " [0.9593366  0.19178048]\n",
      " [0.16942483 0.03385087]\n",
      " [0.9179748  0.18360904]\n",
      " [0.52971417 0.10616466]\n",
      " [0.8248851  0.16515104]\n",
      " [0.98486066 0.196813  ]\n",
      " [0.8179275  0.16376814]\n",
      " [0.08829166 0.01762623]\n",
      " [0.43329442 0.08680777]\n",
      " [0.1853149  0.03703345]\n",
      " [0.9779951  0.19546007]\n",
      " [0.53574073 0.10737374]\n",
      " [0.2949829  0.05902949]\n",
      " [0.89328325 0.1787219 ]\n",
      " [0.426267   0.0853963 ]\n",
      " [0.7152182  0.14330347]\n",
      " [0.26101482 0.05221182]\n",
      " [0.23806988 0.04760866]\n",
      " [0.5608481  0.11240951]\n",
      " [0.584944   0.11724002]\n",
      " [0.44634733 0.08942923]\n",
      " [0.86854184 0.17381841]\n",
      " [0.80201226 0.1606028 ]\n",
      " [0.6010027  0.1204579 ]\n",
      " [0.8506988  0.17027827]\n",
      " [0.26600656 0.05321349]\n",
      " [0.9946605  0.19874312]\n",
      " [0.53071856 0.10636621]\n",
      " [0.05776704 0.0115351 ]\n",
      " [0.12186703 0.02433488]\n",
      " [0.21615049 0.04321318]\n",
      " [0.02831299 0.0056656 ]\n",
      " [0.07449555 0.01487226]\n",
      " [0.04695711 0.00937998]\n",
      " [0.2480424  0.04960909]\n",
      " [0.7232152  0.14489986]\n",
      " [0.2819886  0.05642105]\n",
      " [0.89427197 0.17891766]\n",
      " [0.91501456 0.18302348]\n",
      " [0.8119611  0.16258171]\n",
      " [0.24505004 0.04900881]\n",
      " [0.82389134 0.16495356]\n",
      " [0.32199466 0.06445298]\n",
      " [0.6451345  0.12929446]\n",
      " [0.1595027  0.03186434]\n",
      " [0.9770139  0.19526663]\n",
      " [0.43028256 0.08620284]\n",
      " [0.9416293  0.18828459]\n",
      " [0.46341956 0.09285761]\n",
      " [0.3099857  0.06204159]\n",
      " [0.69921553 0.14010753]\n",
      " [0.06268442 0.0125158 ]\n",
      " [0.8853714  0.17715451]\n",
      " [0.59698856 0.11965368]\n",
      " [0.76913834 0.15405782]\n",
      " [0.65114844 0.13049778]\n",
      " [0.65215063 0.13069831]\n",
      " [0.86656046 0.17342544]\n",
      " [0.67018473 0.13430533]\n",
      " [0.29898268 0.05983248]\n",
      " [0.6912104  0.13850814]\n",
      " [0.3149887  0.06304616]\n",
      " [0.31098622 0.0622425 ]\n",
      " [0.36206284 0.07250013]\n",
      " [0.4804943  0.09628596]\n",
      " [0.11198187 0.02235884]\n",
      " [0.9887819  0.19758534]\n",
      " [0.48752558 0.09769759]\n",
      " [0.36406764 0.07290282]\n",
      " [0.25502646 0.05101026]\n",
      " [0.26001665 0.05201152]\n",
      " [0.8040025  0.16099878]\n",
      " [0.6791978  0.1361073 ]\n",
      " [0.4955615  0.09931075]\n",
      " [0.6721879  0.13470586]\n",
      " [0.37810442 0.07572229]\n",
      " [0.5277053  0.10576161]\n",
      " [0.8467305  0.16949043]\n",
      " [0.13869028 0.02769941]\n",
      " [0.3560492  0.07129227]\n",
      " [0.36607257 0.07330551]\n",
      " [0.94261384 0.18847902]\n",
      " [0.75118136 0.15047878]\n",
      " [0.9485189  0.18964522]\n",
      " [0.83084625 0.16633566]\n",
      " [0.6581632  0.13190113]\n",
      " [0.20022762 0.04002151]\n",
      " [0.21415925 0.04281399]\n",
      " [0.4092038  0.08196907]\n",
      " [0.33300778 0.06666461]\n",
      " [0.20918223 0.04181628]\n",
      " [0.6150498  0.12327168]\n",
      " [0.08040603 0.01605191]]\n",
      "[[0.52247752 0.1044955 ]\n",
      " [0.73826174 0.14765235]\n",
      " [0.74125874 0.14825175]\n",
      " [0.66133866 0.13226773]\n",
      " [0.41258741 0.08251748]\n",
      " [0.67932068 0.13586414]\n",
      " [0.62737263 0.12547453]\n",
      " [0.51448551 0.1028971 ]\n",
      " [0.86013986 0.17202797]\n",
      " [0.13786214 0.02757243]\n",
      " [0.81218781 0.16243756]\n",
      " [0.07792208 0.01558442]\n",
      " [0.63736264 0.12747253]\n",
      " [0.97402597 0.19480519]\n",
      " [0.93906094 0.18781219]\n",
      " [0.9000999  0.18001998]\n",
      " [0.28171828 0.05634366]\n",
      " [0.88411588 0.17682318]\n",
      " [0.76223776 0.15244755]\n",
      " [0.32067932 0.06413586]\n",
      " [0.55044955 0.11008991]\n",
      " [0.17582418 0.03516484]\n",
      " [0.37262737 0.07452547]\n",
      " [0.52847153 0.10569431]\n",
      " [0.21178821 0.04235764]\n",
      " [0.23676324 0.04735265]\n",
      " [0.1028971  0.02057942]\n",
      " [0.98701299 0.1974026 ]\n",
      " [0.9030969  0.18061938]\n",
      " [0.94805195 0.18961039]\n",
      " [0.34765235 0.06953047]\n",
      " [0.14085914 0.02817183]\n",
      " [0.62237762 0.12447552]\n",
      " [0.5004995  0.1000999 ]\n",
      " [0.37162837 0.07432567]\n",
      " [0.1998002  0.03996004]\n",
      " [0.68831169 0.13766234]\n",
      " [0.58541459 0.11708292]\n",
      " [0.9020979  0.18041958]\n",
      " [0.06093906 0.01218781]\n",
      " [0.32967033 0.06593407]\n",
      " [0.0979021  0.01958042]\n",
      " [0.31368631 0.06273726]\n",
      " [0.97502498 0.195005  ]\n",
      " [0.3006993  0.06013986]\n",
      " [0.27872128 0.05574426]\n",
      " [0.92507493 0.18501499]\n",
      " [0.6023976  0.12047952]\n",
      " [0.44055944 0.08811189]\n",
      " [0.83816184 0.16763237]\n",
      " [0.57142857 0.11428571]\n",
      " [0.88011988 0.17602398]\n",
      " [0.26273726 0.05254745]\n",
      " [0.57942058 0.11588412]\n",
      " [0.02497502 0.004995  ]\n",
      " [0.03196803 0.00639361]\n",
      " [0.61838162 0.12367632]\n",
      " [0.01198801 0.0023976 ]\n",
      " [0.22277722 0.04455544]\n",
      " [0.82117882 0.16423576]\n",
      " [0.2977023  0.05954046]\n",
      " [0.05594406 0.01118881]\n",
      " [0.54345654 0.10869131]\n",
      " [0.21078921 0.04215784]\n",
      " [0.60539461 0.12107892]\n",
      " [0.69330669 0.13866134]\n",
      " [0.66333666 0.13266733]\n",
      " [0.86713287 0.17342657]\n",
      " [0.07192807 0.01438561]\n",
      " [0.54445554 0.10889111]\n",
      " [0.10889111 0.02177822]\n",
      " [0.49450549 0.0989011 ]\n",
      " [0.59140859 0.11828172]\n",
      " [0.74225774 0.14845155]\n",
      " [0.29370629 0.05874126]\n",
      " [0.29070929 0.05814186]\n",
      " [0.65334665 0.13066933]\n",
      " [0.04095904 0.00819181]\n",
      " [0.59040959 0.11808192]\n",
      " [0.30869131 0.06173826]\n",
      " [0.68031968 0.13606394]\n",
      " [0.06793207 0.01358641]\n",
      " [0.27672328 0.05534466]\n",
      " [0.06893107 0.01378621]\n",
      " [0.31968032 0.06393606]\n",
      " [0.54945055 0.10989011]\n",
      " [0.999001   0.1998002 ]\n",
      " [0.71528472 0.14305694]\n",
      " [0.75424575 0.15084915]\n",
      " [0.32867133 0.06573427]\n",
      " [0.38361638 0.07672328]\n",
      " [0.45254745 0.09050949]\n",
      " [0.52347652 0.1046953 ]\n",
      " [0.21978022 0.04395604]\n",
      " [0.78821179 0.15764236]\n",
      " [0.43756244 0.08751249]\n",
      " [0.76523477 0.15304695]\n",
      " [0.08991009 0.01798202]\n",
      " [0.06493506 0.01298701]\n",
      " [0.82717283 0.16543457]\n",
      " [0.71728272 0.14345654]\n",
      " [0.35264735 0.07052947]\n",
      " [0.93706294 0.18741259]\n",
      " [0.25774226 0.05154845]\n",
      " [0.63636364 0.12727273]\n",
      " [0.64535465 0.12907093]\n",
      " [0.55544456 0.11108891]\n",
      " [0.96003996 0.19200799]\n",
      " [0.16983017 0.03396603]\n",
      " [0.91808192 0.18361638]\n",
      " [0.52947053 0.10589411]\n",
      " [0.82417582 0.16483516]\n",
      " [0.98601399 0.1972028 ]\n",
      " [0.81718282 0.16343656]\n",
      " [0.08791209 0.01758242]\n",
      " [0.43356643 0.08671329]\n",
      " [0.18581419 0.03716284]\n",
      " [0.97902098 0.1958042 ]\n",
      " [0.53546454 0.10709291]\n",
      " [0.2957043  0.05914086]\n",
      " [0.89310689 0.17862138]\n",
      " [0.42657343 0.08531469]\n",
      " [0.71428571 0.14285714]\n",
      " [0.26173826 0.05234765]\n",
      " [0.23876124 0.04775225]\n",
      " [0.56043956 0.11208791]\n",
      " [0.58441558 0.11688312]\n",
      " [0.44655345 0.08931069]\n",
      " [0.86813187 0.17362637]\n",
      " [0.8011988  0.16023976]\n",
      " [0.6003996  0.12007992]\n",
      " [0.85014985 0.17002997]\n",
      " [0.26673327 0.05334665]\n",
      " [0.996004   0.1992008 ]\n",
      " [0.53046953 0.10609391]\n",
      " [0.05694306 0.01138861]\n",
      " [0.12187812 0.02437562]\n",
      " [0.21678322 0.04335664]\n",
      " [0.02697303 0.00539461]\n",
      " [0.07392607 0.01478521]\n",
      " [0.04595405 0.00919081]\n",
      " [0.24875125 0.04975025]\n",
      " [0.72227772 0.14445554]\n",
      " [0.28271728 0.05654346]\n",
      " [0.89410589 0.17882118]\n",
      " [0.91508492 0.18301698]\n",
      " [0.81118881 0.16223776]\n",
      " [0.24575425 0.04915085]\n",
      " [0.82317682 0.16463536]\n",
      " [0.32267732 0.06453546]\n",
      " [0.64435564 0.12887113]\n",
      " [0.15984016 0.03196803]\n",
      " [0.97802198 0.1956044 ]\n",
      " [0.43056943 0.08611389]\n",
      " [0.94205794 0.18841159]\n",
      " [0.46353646 0.09270729]\n",
      " [0.31068931 0.06213786]\n",
      " [0.6983017  0.13966034]\n",
      " [0.06193806 0.01238761]\n",
      " [0.88511489 0.17702298]\n",
      " [0.5964036  0.11928072]\n",
      " [0.76823177 0.15364635]\n",
      " [0.65034965 0.13006993]\n",
      " [0.65134865 0.13026973]\n",
      " [0.86613387 0.17322677]\n",
      " [0.66933067 0.13386613]\n",
      " [0.2997003  0.05994006]\n",
      " [0.69030969 0.13806194]\n",
      " [0.31568432 0.06313686]\n",
      " [0.31168831 0.06233766]\n",
      " [0.36263736 0.07252747]\n",
      " [0.48051948 0.0961039 ]\n",
      " [0.11188811 0.02237762]\n",
      " [0.99000999 0.198002  ]\n",
      " [0.48751249 0.0975025 ]\n",
      " [0.36463536 0.07292707]\n",
      " [0.25574426 0.05114885]\n",
      " [0.26073926 0.05214785]\n",
      " [0.8031968  0.16063936]\n",
      " [0.67832168 0.13566434]\n",
      " [0.4955045  0.0991009 ]\n",
      " [0.67132867 0.13426573]\n",
      " [0.37862138 0.07572428]\n",
      " [0.52747253 0.10549451]\n",
      " [0.84615385 0.16923077]\n",
      " [0.13886114 0.02777223]\n",
      " [0.35664336 0.07132867]\n",
      " [0.36663337 0.07332667]\n",
      " [0.94305694 0.18861139]\n",
      " [0.75024975 0.15004995]\n",
      " [0.94905095 0.18981019]\n",
      " [0.83016983 0.16603397]\n",
      " [0.65734266 0.13146853]\n",
      " [0.2007992  0.04015984]\n",
      " [0.21478521 0.04295704]\n",
      " [0.40959041 0.08191808]\n",
      " [0.33366633 0.06673327]\n",
      " [0.20979021 0.04195804]\n",
      " [0.61438561 0.12287712]\n",
      " [0.07992008 0.01598402]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 划分训练集和测试集\n",
    "train_x, test_x, train_y, test_y = train_test_split(data, target, test_size = 0.20, random_state = 42)\n",
    "\n",
    "# 建立 LSTM 模型\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(5, 1)))\n",
    "model.add(Dense(32))\n",
    "model.add(Dense(2))\n",
    "\n",
    "# 编译模型\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# 训练模型\n",
    "model.fit(train_x, train_y, epochs=100, batch_size=64, verbose=2)\n",
    "\n",
    "# 测试模型\n",
    "predict = model.predict(test_x)\n",
    "\n",
    "# 打印预测结果\n",
    "print(predict)\n",
    "print(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.52268296 0.1047539 ]\n",
      " [0.73920053 0.14808954]\n",
      " [0.7421964  0.14868708]\n",
      " [0.66217095 0.1327027 ]\n",
      " [0.41221455 0.08257381]]\n",
      "[[0.52247752 0.1044955 ]\n",
      " [0.73826174 0.14765235]\n",
      " [0.74125874 0.14825175]\n",
      " [0.66133866 0.13226773]\n",
      " [0.41258741 0.08251748]]\n"
     ]
    }
   ],
   "source": [
    "print(predict[:5,])\n",
    "print(test_y[:5,])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "magnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
